{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Cargue de datos y vectorización, tokenizacion"
      ],
      "metadata": {
        "id": "x9-qeKFF_ZiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "# Tokenizador BERT preentrenado en español\n",
        "tokenizer = BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-uncased')\n",
        "\n",
        "# Modelo BERT preentrenado en español\n",
        "model = BertModel.from_pretrained('dccuchile/bert-base-spanish-wwm-uncased')\n",
        "\n",
        "df_train= pd.read_csv('./Insumos/train.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7FDXCKwVKBp",
        "outputId": "fad3f209-c0ef-4404-e7e3-88cc0394a08a"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def embedding(texto):\n",
        "  # Tokenizar y obtener embeddings para los textos\n",
        "  tokens = tokenizer.encode(texto, add_special_tokens=True)\n",
        "  input_ids = torch.tensor([tokens])\n",
        "  with torch.no_grad():\n",
        "      outputs = model(input_ids)\n",
        "  # Obtener los embeddings de los tokens [CLS]\n",
        "  embedding = outputs.last_hidden_state.mean(dim=1).squeeze()\n",
        "  return embedding"
      ],
      "metadata": {
        "id": "yY2erIN4Ysbh"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['query_embedding']=df_train['query'].apply(lambda x: embedding(x))"
      ],
      "metadata": {
        "id": "ioWSmviGWGVH"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['document_embedding']=df_train['document'].apply(lambda x: embedding(x))"
      ],
      "metadata": {
        "id": "h130rdfvZXzI"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Busqueda del documento con mayor simulitud y ranqueo\n",
        "def search_docs_onprimse(df, user_query, top_n=3, to_print=True):\n",
        "    embedding = df.query(f'query==\"{user_query}\"')\\\n",
        "                    [['query','query_embedding']].drop_duplicates(subset='query')\\\n",
        "                    .query_embedding.values[0]\n",
        "    df[\"similarities\"] = df.document_embedding.apply(lambda x: F.cosine_similarity(x, embedding,dim=0))\n",
        "\n",
        "    res = (\n",
        "        df.sort_values(\"similarities\", ascending=False)\n",
        "        .head(top_n)\n",
        "    )\n",
        "    if to_print:\n",
        "        display(res)\n",
        "    return res"
      ],
      "metadata": {
        "id": "OVicR2SwbfUo"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resuelto= pd.DataFrame()\n",
        "preguntas={}\n",
        "mmr=[]\n",
        "for query in df_train['query'].unique():\n",
        "    respuestaTemporal= search_docs_onprimse(df_train,query, to_print=False)\n",
        "    documentos= respuestaTemporal.document.to_list()\n",
        "    preguntas[query]= documentos\n",
        "    try:\n",
        "        valor= respuestaTemporal.reset_index(drop=True)\\\n",
        "                .query('label==1').index[0]+1\n",
        "        mmrTemporal= 1/valor\n",
        "    except:\n",
        "        mmrTemporal=0\n",
        "    mmr.append(mmrTemporal)"
      ],
      "metadata": {
        "id": "ML6WLrMSbj74"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Especificamos la ruta del archivo JSON\n",
        "ruta_archivo = \"./Ejecuciones/results_train_ada_v2.json\"\n",
        "\n",
        "# Guardamos el diccionario como JSON en el archivo\n",
        "with open(ruta_archivo,\"w\") as archivo:\n",
        "    json.dump(preguntas, archivo)\n",
        "\n",
        "print(\"Resultados guardados en results.json\")\n",
        "print('La media de los MMR es :',sum(mmr)/len(mmr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbMG8dTDdOTA",
        "outputId": "98df360c-ece9-43f9-bedb-85442f4a84f5"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados guardados en results.json\n",
            "La media de los MMR es : 0.33875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "enqH7XIsmsZl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}